{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_input_data(csv_path):\n",
    "    img_features = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    img_features = img_features.assign(key=1).merge(img_features.assign(key=1), on=\"key\", suffixes=[\"_A\", \"_B\"]).drop(\"key\", axis=1)\n",
    "    img_features = img_features[img_features[\"img_id_A\"] != img_features[\"img_id_B\"]]\n",
    "    \n",
    "    return img_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = merge_input_data(\"./HumanObserved-Dataset/HumanObserved-Features-Data/HumanObserved-Features-Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_data(csv_paths):\n",
    "    labeled_data = pd.read_csv(csv_paths[0])\n",
    "    for path in csv_paths[1:]:\n",
    "        labeled_data = pd.concat([labeled_data, pd.read_csv(path)])\n",
    "    \n",
    "    return labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = [\"./HumanObserved-Dataset/HumanObserved-Features-Data/diffn_pairs.csv\", \"./HumanObserved-Dataset/HumanObserved-Features-Data/same_pairs.csv\"]\n",
    "labeled_data = read_labeled_data(csv_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_writer_pairs(img_features, labeled_data):\n",
    "    # filter from all combinations of writer pairs\n",
    "    a = img_features[\"img_id_A\"] + img_features[\"img_id_B\"]\n",
    "    b = labeled_data[\"img_id_A\"] + labeled_data[\"img_id_B\"]\n",
    "    feature_set = img_features[a.isin(b)]\n",
    "    \n",
    "    feature_set = pd.merge(feature_set, labeled_data, on=[\"img_id_A\", \"img_id_B\"])\n",
    "    \n",
    "    feature_set[\"writer_A\"] = [elm[:4] for elm in feature_set[\"img_id_A\"]]\n",
    "    return feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = filter_writer_pairs(img_features, labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(feature_set):\n",
    "    unique = feature_set[\"writer_A\"].unique()\n",
    "    unique = np.random.permutation(unique)\n",
    "\n",
    "    # training validation and test sets split\n",
    "    tr_idx = int(0.8 * unique.shape[0])\n",
    "    tr_s = unique[:tr_idx]\n",
    "\n",
    "    training_set = feature_set.loc[feature_set[\"writer_A\"].isin(tr_s)]\n",
    "\n",
    "\n",
    "    val_idx = tr_idx + int(0.1 * unique.shape[0])\n",
    "    val_s = unique[tr_idx: val_idx]\n",
    "    validation_set = feature_set.loc[feature_set[\"writer_A\"].isin(val_s)]\n",
    "\n",
    "\n",
    "    test_s = unique[val_idx:]\n",
    "    test_set = feature_set.loc[feature_set[\"writer_A\"].isin(test_s)]\n",
    "    \n",
    "    del training_set[\"writer_A\"]\n",
    "    del validation_set[\"writer_A\"]\n",
    "    del test_set[\"writer_A\"]\n",
    "    \n",
    "    return training_set, validation_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, validation_set, test_set = train_val_test_split(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_labels(dataset):\n",
    "    feature_columns = [ (\"f%d_%s\" % (idx, label)) for label in [\"A\", \"B\"] for idx in range(1, 10) ]\n",
    "\n",
    "    return np.array(training_set.loc[:, feature_columns]), np.array(training_set[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_features_and_labels(training_set)\n",
    "X_val, y_val = get_features_and_labels(validation_set)\n",
    "X_test, y_test = get_features_and_labels(test_set)\n",
    "# i = 0\n",
    "# num = X_train.shape[0] // 100\n",
    "\n",
    "# loss = 0\n",
    "# while i < X_train.shape[0]:\n",
    "#     x_tr = X_train[i:i+num]\n",
    "#     y_tr = y_train[i:i+num]\n",
    "#     W = np.ones((x_tr.shape[1], 1))\n",
    "#     prd = np.dot(x_tr, W)\n",
    "#     h_x = 1 / (1 + np.exp(-prd))\n",
    "\n",
    "# #     loss += \n",
    "#     print(np.sum(-np.log(h_x) * y_tr - np.log(1 - h_x) * (1 - y_tr)))\n",
    "#     i += num\n",
    "\n",
    "# print(loss)\n",
    "# # from scipy.sparse import csr_matrix\n",
    "\n",
    "# # feature_columns = [ (\"f%d_%s\" % (idx, label)) for label in [\"A\", \"B\"] for idx in range(1, 10) ]\n",
    "\n",
    "# # X_train, y_train = csr_matrix(training_set.loc[:, feature_columns]), csr_matrix(training_set[\"target\"])\n",
    "\n",
    "\n",
    "# # W = csr_matrix(np.ones((X_train.shape[1], 1)))\n",
    "\n",
    "# # prd = np.dot(X_train, W)\n",
    "\n",
    "# # h_x = 1 / (2 + np.expm1(-prd))\n",
    "\n",
    "\n",
    "# # # np.dot(X_train)\n",
    "# # loss = np.sum(-y_train * np.log(h_x) - (1 - y) * np.log(1 - h_x))\n",
    "# # print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
